# AVM Project
# Automated Valuation Model (AVM) for Real Estate

Production-ready machine learning system for automated property valuation in Nigeria.

## ğŸ—ï¸ Architecture

```
avm-project/
â”œâ”€â”€ README.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ Makefile                      # train / test / deploy shortcuts
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py               # GCP project, dataset, table names
â”‚   â”œâ”€â”€ features.py               # Canonical feature list
â”‚   â”œâ”€â”€ model_config.py           # Hyperparameters, CV, thresholds
â”‚   â””â”€â”€ env.py                    # Env-specific config (dev/stg/prod)
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ auth/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ gcp_auth.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ bigquery_client.py
â”‚   â”‚   â”œâ”€â”€ loader.py
â”‚   â”‚   â”œâ”€â”€ validator.py
â”‚   â”‚   â””â”€â”€ contracts/            # ğŸ” Data contracts
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ raw_schema.py
â”‚   â”‚       â”œâ”€â”€ feature_schema.py
â”‚   â”‚       â””â”€â”€ prediction_schema.py
â”‚   â”‚
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cleaners.py
â”‚   â”‚   â”œâ”€â”€ transformers.py
â”‚   â”‚   â”œâ”€â”€ imputers.py
â”‚   â”‚   â””â”€â”€ validators.py         # Inference-safe checks
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ engineering.py
â”‚   â”‚   â”œâ”€â”€ selectors.py
â”‚   â”‚   â””â”€â”€ spatial.py            # Amenities, geo, address features
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”œâ”€â”€ linear.py
â”‚   â”‚   â”œâ”€â”€ residual.py
â”‚   â”‚   â”œâ”€â”€ ensemble.py
â”‚   â”‚   â”œâ”€â”€ trainer.py
â”‚   â”‚   â””â”€â”€ registry.py           # Model + artifact registration
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â”œâ”€â”€ diagnostics.py
â”‚   â”‚   â””â”€â”€ drift.py              # Feature & prediction drift
â”‚   â”‚
â”‚   â”œâ”€â”€ serving/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ request_parser.py     # Vertex request normalization
â”‚   â”‚   â”œâ”€â”€ response_formatter.py
â”‚   â”‚   â””â”€â”€ guards.py             # Fail-safe prediction logic
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logging.py
â”‚       â”œâ”€â”€ helpers.py
â”‚       â””â”€â”€ monitoring.py         # Stats â†’ BigQuery / logs
â”‚
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train_pipeline.py
â”‚   â”œâ”€â”€ inference_pipeline.py
â”‚   â””â”€â”€ validation_pipeline.py    # Schema + drift validation
â”‚
â”œâ”€â”€ deployment/
â”‚   â”œâ”€â”€ predictor.py              # Vertex AI Predictor
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â””â”€â”€ vertex_config.yaml        # Machine, autoscaling, traffic split
â”‚
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ vYYYY_MM_DD/               # ğŸ”– Versioned artifacts
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ linreg.pkl
â”‚       â”‚   â”œâ”€â”€ residual_lgbm.pkl
â”‚       â”‚   â””â”€â”€ smearing.pkl
â”‚       â”œâ”€â”€ preprocessors/
â”‚       â”‚   â”œâ”€â”€ imputer.pkl
â”‚       â”‚   â””â”€â”€ scaler.pkl
â”‚       â””â”€â”€ metadata/
â”‚           â”œâ”€â”€ feature_names.json
â”‚           â”œâ”€â”€ feature_lineage.json
â”‚           â”œâ”€â”€ training_stats.json
â”‚           â””â”€â”€ model_card.md      # Explainability + limitations
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_evaluation.ipynb
â”‚   â””â”€â”€ 04_error_analysis.ipynb
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_data/
â”‚   â”œâ”€â”€ test_preprocessing/
â”‚   â”œâ”€â”€ test_features/
â”‚   â”œâ”€â”€ test_models/
â”‚   â”œâ”€â”€ test_serving/
â”‚   â””â”€â”€ test_pipeline/
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ train.py
    â”œâ”€â”€ predict.py
    â”œâ”€â”€ validate_data.py           # Contract + drift checks
    â”œâ”€â”€ upload_to_gcs.py
    â””â”€â”€ deploy_to_vertex.py

```

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone <repo-url>
cd avm-project

# Install dependencies
pip install -r requirements.txt
```

### Training

**From BigQuery:**
```bash
python scripts/train.py --project-id your-project-id
```

**From CSV:**
```bash
python scripts/train.py --csv data/properties.csv
```

**With Colab authentication:**
```bash
python scripts/train.py --use-colab
```

### Prediction

```bash
python scripts/predict.py --input data/new_properties.csv --output predictions.csv
```

### Upload to GCS

```bash
python scripts/upload_to_gcs.py --bucket your-bucket --prefix models
```

## ğŸ“Š Model Architecture

The system uses a two-stage ensemble approach:

1. **Linear Regression** with smearing correction for bias
2. **LightGBM Residual Model** to capture non-linear patterns

**Final Prediction = Linear Prediction + Residual Correction**

## ğŸ”§ Configuration

Edit `config/settings.py` to customize:
- GCP project settings
- BigQuery dataset/table
- Geographic bounds
- Model hyperparameters

## ğŸ“ˆ Features

### Input Features
- Property configuration (beds, baths, toilets)
- Geographic coordinates
- Distance to amenities (schools, hospitals, malls, etc.)
- Address-based features

### Engineered Features
- Room totals and aggregates
- Consistency checks (list vs detail)
- Accessibility scores
- Log-transformed distances

## ğŸ¯ Evaluation Metrics

- **MAE**: Mean Absolute Error
- **RMSE**: Root Mean Squared Error
- **RÂ²**: Coefficient of Determination
- **MRE**: Median Relative Error
- **MAPE**: Mean Absolute Percentage Error
- **Tier-based analysis**: Error breakdown by price tier

## ğŸ³ Deployment

### Build Container

```bash
cd deployment
docker build -t avm-predictor .
```

### Deploy to Vertex AI

```bash
# Upload models to GCS
python scripts/upload_to_gcs.py

# Deploy endpoint (use GCP Console or gcloud CLI)
```

## ğŸ“ Environment Variables

Create `.env` file:

```bash
GCP_PROJECT_ID=your-project-id
GCP_REGION=us-central1
BIGQUERY_DATASET=your_dataset
BIGQUERY_TABLE=master_listings
GCS_BUCKET=your-bucket
LOG_LEVEL=INFO
```

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/

# Run with coverage
pytest tests/ --cov=src
```

## ğŸ“š Documentation

- **Training Pipeline**: See `pipelines/train_pipeline.py`
- **Model Details**: See `src/models/`
- **Feature Engineering**: See `src/features/engineering.py`
- **API Documentation**: See `deployment/predictor.py`



